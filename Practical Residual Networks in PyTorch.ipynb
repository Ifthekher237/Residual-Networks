{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fea349",
   "metadata": {},
   "source": [
    "This is the ResNet model that we are going to build.\n",
    "\n",
    "![resnet](mini-resnet-image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ef5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 10  # to decrease the computation time 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "#CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./',\n",
    "                                            train=True,\n",
    "                                            transform=transform,\n",
    "                                            download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./',\n",
    "                                           train=False,\n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db675fc",
   "metadata": {},
   "source": [
    "**transforms.Pad(4):** This transformation pads the image with a border of 4 pixels on all sides. Padding is often used to ensure that the spatial dimensions of the input images are consistent, which can be important for certain types of neural network architectures.\n",
    "\n",
    "**transforms.RandomHorizontalFlip():** This transformation randomly flips the image horizontally with a probability of 0.5. Horizontal flipping is a common data augmentation technique used to increase the variability of the training data and improve the robustness of the model to variations in the orientation of objects within the images.\n",
    "\n",
    "**transforms.RandomCrop(32):** This transformation randomly crops the image to a size of 32x32 pixels. Random cropping is another data augmentation technique that helps the model learn to focus on different parts of the image and improves its ability to generalize to unseen data.\n",
    "\n",
    "**transforms.ToTensor():** This transformation converts the image from a PIL Image object (or numpy array) to a PyTorch tensor. PyTorch tensors are the primary data structure used for representing images and other types of data in PyTorch, and they are compatible with the operations and functions provided by PyTorch's tensor library.\n",
    "\n",
    "**download=True:** This parameter indicates whether to download the dataset if it's not already present in the specified root directory. If set to True, it will download the CIFAR-10 dataset from the internet and save it in the specified root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44686b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, the first thing you might notice is that throughout the whole network we're using 3*3 convolutional layers.\n",
    "# So, let's go ahead and define a function to perform 3*3 convolution and then we can use this function all over again.\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1): \n",
    "    # stride=1 means, if stride is not given, by default it'll be set to 1\n",
    "    \n",
    "    \n",
    "    # since all over we'll be using 3x3 conv layers, so always kernel size=3\n",
    "    # we're taking stride value from the input and applying same padding to prreserve the size of input.\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "   \n",
    "\n",
    "# let's define our residual block. This consists of two convolutional layers,\n",
    "# and each of these is followed by a batch normalization and a ReLU activation function \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsampling=None):\n",
    "        # if not given, by default downsampling is set to None\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # just to inheirt everything from nn.Module.\n",
    "        \n",
    "        # Let's start defining our layers.\n",
    "        # first conv layer\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels) #takes the inputs of number of features maps on which BN will be applied\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        # Second conv layer\n",
    "        # for the 2nd conv layer, the stride is always 1. \n",
    "        # so by default it's always 1 as we set it to be 1 if not given\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        #takes the inputs of number of features maps on which BN will be applied\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels) \n",
    "        \n",
    "        # finally also specify whether there's a downsampling layer or not.\n",
    "        self.downsampling = downsampling\n",
    "        \n",
    "\n",
    "    # Let's define the forward function in charge of the forward propagation\n",
    "    def forward(self, x): \n",
    "        # x=for the first one,it's the image but for the further layer it's \n",
    "        # just the previous feature maps.\n",
    "\n",
    "        #first, save the input as we need to add it later on.\n",
    "        residual = x.clone()  # makes a clone of x and save it to residual variable\n",
    "            \n",
    "        # let's start running the layers.\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "            \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # Here, at this step we do the additon and then perform the ReLu.\n",
    "        # But, sometimes, if neede, before the additon we need to downsample\n",
    "        # so set a condition to do downsampling if needed\n",
    "        if self.downsampling:\n",
    "            residual = self.downsampling(x)\n",
    "            \n",
    "        # now, do the addition\n",
    "        out = out + residual\n",
    "            \n",
    "        # finally, run it through ReLu activation function\n",
    "        out = self.relu(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b551f5",
   "metadata": {},
   "source": [
    "In the previous cell, we coded a residual block, which consists of two convolutional layers, and each of them has batch normalization and ReLU. Now, we're going to take this residual block and replicate it again to construct our full residual network. Now here, remember, besides the 6 residual blocks, we have the very first convolutional layer, which processes the image. And at the end, we have average pooling rather than max pooling. So the last layer consists of average pooling. And then, we take this result of average pooling\n",
    "and we run it through a fully connected layer, which is the classification layer to classify 10 classes. Here we're using CIFAR-10, so we have 10 classes.\n",
    "\n",
    "Recap about average pooling:\n",
    "![avgpool](avg-pooling.png)\n",
    "\n",
    "## In ResNet, kernal size = size of the feature map\n",
    "In our case size of the feature map afer the 3rd layer is 8x8. Why? size of the input image is 32x32. At the beginning of 2nd layer we downsample it by 2. Hence size of the feature map becomes 16x16. At the beginning of 3rd layer we downsample it again by 2. Hence size of the feature map becomes 8x8. So during average pooling we have feature maps of size 8x8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the class of this residual network\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10): # this class takes input as residual block, list of layers\n",
    "                                                       # and # of classification classes, by default which is set to 10 as we're using CIFAR-10 dataset\n",
    "        \"\"\"\n",
    "        layers will be a list: [2,2,2]. That means 2 block for each layer.  So the number of  the list is the number \n",
    "        of layers in the network and  each element specifies the number of block in each layer.\n",
    "        \n",
    "        NOTE: a layer consists of 2 residual blocks and each residual blocks consists of 2 conv layers.\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        #let's define the attributes\n",
    "              \n",
    "        self.in_channels = 16                # number of input channels for the first residual block       \n",
    "        self.conv = conv3x3(3,16)            # first conv layer, where input channels are 3 as this is an RBG image\n",
    "                                             # and # of output channels are 16. This layer also has BatchNorm and ReLu.\n",
    "        self.bn = nn.BatchNorm2d(16)         # since we have 16 feature maps as output\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        \n",
    "        # Let's define the layers (each laeyr has different # of channels)\n",
    "        self.layer1 = self.make_layer(block,16, layers[0], stride=1) # layers[0] specifies the # of blocks for 1st layer\n",
    "        self.layer2 = self.make_layer(block,32, layers[1],stride=2)  # since we need to do downsampling, so stride is set to 2\n",
    "        self.layer3 = self.make_layer(block,64, layers[2],stride=2)\n",
    "        \n",
    "        # Let's define the avg pooling\n",
    "        self.avg_pool = nn.AvgPool2d(8)         # explanation for why kernel size is 8 given above cell\n",
    "        \n",
    "        # Let's define the fully connected layer/classification layer\n",
    "        self.fc = nn.Linear(64, num_classes)  # since after the 3rd layes we have 64 channels and \n",
    "                                              # after avg pool we get only 64 value. so the number of input dimension is 64 and \n",
    "                                              # since CIFAR-10 dataset has 10 classes only, so output dimension is 10\n",
    "        \n",
    "        \n",
    "    #you can guess what will be the inputs of this function as we used this function in the previous lines.\n",
    "    def make_layer(self, block, out_channels, num_blocks, stride=1):\n",
    "        \"\"\"\n",
    "        function to make a layer. Our network has 3 layers each with 2 block.\n",
    "        \"\"\"\n",
    "            \n",
    "        # Explanation for the downsampling layer is given below.\n",
    "        downsampling = None\n",
    "        if (self.in_channels != out_channels) or (stride != 1):\n",
    "            downsampling = nn.Sequential(conv3x3(self.in_channels, out_channels, stride = stride), nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "        residual_blocks = []  # to add all the residual blocks of a layer.\n",
    "        residual_blocks.append(block(self.in_channels, out_channels, stride=stride, downsampling=downsampling)) # appending the first residual block. See the ResidualBlock() class what input it takes.\n",
    "            \n",
    "        # as of now, we're using in_channles=16, but we need to change to after a specific block\n",
    "        self.in_channels = out_channels\n",
    "            \n",
    "        # now append the 2nd residual block\n",
    "        residual_blocks.append(block(self.in_channels, out_channels)) # we don't need to specify stride and downsampling for the 2nd block a layer.\n",
    "                                                                          # Because for the 2nd block a layer by default stride=1 and no downsampling layer is required.\n",
    "        \n",
    "        self.in_channels = out_channels\n",
    "        \n",
    "        # now appending the rest of the residual block\n",
    "        for i in range(2, num_blocks):\n",
    "            residual_blocks.append(block(out_channels, out_channels))\n",
    "        \n",
    "        return nn.Sequential(*residual_blocks)  # explanation given below why * is used.\n",
    "            \n",
    "            \n",
    "    #let's define the forward function\n",
    "    def forward(self, x):\n",
    "        # x can be either the image or feature maps from the previous steps\n",
    "            \n",
    "        # for the initial conv layer\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "            \n",
    "        # then run through the 1st, 2nd, 3rd layer\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "            \n",
    "        # then run through avg pooling\n",
    "        out = self.avg_pool(out)\n",
    "            \n",
    "        # reshaping the output before passing through classification layer.\n",
    "        out = out.view(out.size(0),-1)  #out.size(0)==> batch size\n",
    "            \n",
    "        # then run through classification layer\n",
    "        out = self.fc(out)\n",
    "            \n",
    "        return out       \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb05020",
   "metadata": {},
   "source": [
    "Initially We set downsampling to none as a default. Then we'll determine whether downsampling is necessary based on certain conditions (check the theoretical lectures to get the understanding of when downsampling is needed).\n",
    "\n",
    "**1. Mismatched Input and Output Channels:**\n",
    "    If the number of input channels doesn't match the number of output channels, then downsampling is needed.\n",
    "\n",
    "**2. Mismatched in Input and Output Feature Map Sizes:**\n",
    "    When the size of the input feature map differs from the size of the output feature map, then downsampling is needed as well. We check this distinction by examining the stride parameter. A stride value of one indicates no downsampling has occured, while a stride of two implies downsampling has occurred.\n",
    "\n",
    "\n",
    "If any of these conditions occure then we need to downsample. To encapsulate these conditions effectively, we utilize a logical \"or\" operation.\n",
    "\n",
    "the downsampling layer is just a convolutional layer with the stride equal to the stride of the input(first block of the layer). So if we are using a stride of two, that means we're also going to use a stride of two for the downsampling. The number of output channels equals to the output channels of\n",
    "the layer.\n",
    "\n",
    "And then we wanna follow this by a batch normalization layer. To run these 2 operation one after another we put them together in nn.Sequential()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84216fcf",
   "metadata": {},
   "source": [
    "In Python, when you use a star (*) before an iterable (like a list), it's called unpacking. It essentially expands the iterable into individual elements. This is particularly useful when you want to pass multiple arguments to a function or, in this case, multiple layers to the nn.Sequential constructor.\n",
    "\n",
    "Here's an example to illustrate:\n",
    "![starr](star.png)\n",
    "\n",
    "In this example, nn.Sequential(\\*residual_blocks) is equivalent to nn.Sequential(residual_block1, residual_block2, residual_block3). The star (*) operator allows us to avoid explicitly listing each layer separately and makes the code more concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a2c507",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create an object of ResNet class\n",
    "# ResNet takes block as 1st input. so pass the ResidualBlock class, then we pass the 3 layers and by default # of classification is set to 10\n",
    "model = ResNet(ResidualBlock, [2,2,2]).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()   # crossEntropy Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)      # Adam optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead00da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with the training\n",
    "decay = 0\n",
    "model.train() # since we're using batch normalization, we need to specify the mode.\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Decay the learning rate by a factor of 0.5 every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        decay+=1\n",
    "        optimizer.param_groups[0]['lr'] = learning_rate * (0.5**decay) # decaying the learning rate\n",
    "        print(\"The new learning rate is {}\".format(optimizer.param_groups[0]['lr']))\n",
    "        \n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(\"Epoch [{}/{}], step [{}/{}] Loss: {:.4f}\"\n",
    "                 .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5b5fb",
   "metadata": {},
   "source": [
    "param_groups: a List containing all parameter groups where each parameter group is a Dict. Each parameter group contains metadata specific to the optimizer, such as learning rate and weight decay, as well as a List of parameter IDs of the parameters in the group.\n",
    "\n",
    "*type(optimizer.param_groups)* ==> list\n",
    "\n",
    "*type(optimizer.param_groups[0])* ==> dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6898868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():   # as we don't want any gradient computations and this makes the compution much faster\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0) #increamenting total images which is basically how many images we have in the batch\n",
    "        correct += (predicted == labels).sum().item()  # increamenting the correct values. see the CNN section\n",
    "\n",
    "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1aafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f2e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1673e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734d8f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
